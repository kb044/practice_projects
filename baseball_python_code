#import libraries
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
#!pip install xgboost
import xgboost
from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import GridSearchCV

#import data
df = pd.read_csv("Hitters.csv")

#exploratory analysis
df.describe()
#drop null values 
df = df.dropna()

#histograms 
plt.hist([df['Hits'],df['AtBat'],df['Runs']] , bins = 4,
label= ['Hits',	'AtBat','Runs'])
plt.legend()
plt.show()

df.hist(column = 'Hits', by = 'League', bins=10)
plt.show()

hits_by_league = df.groupby('League')
for name, group in hits_by_league: plt.hist(group['Hits'], bins=10, label=name) 
plt.legend()
plt.title("Hits by League")
plt.xlabel("Hits")
plt.ylabel("Count")

plt.scatter(df['Hits'], df['AtBat'])
plt.ylabel('At Bats')
plt.xlabel('Hits')
plt.title("Hits vs At Bats")
plt.show()

#create correlation matrix drop non-numeric columns
df_num = df.drop(columns=['League','Division','NewLeague'])
matrix = df_num.corr()

plt.figure(figsize=(10,8))
sns.heatmap(matrix, annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.2)
plt.title("Correlation Heatmap")
plt.show()

#variables by league
df.groupby("League")[['AtBat','Hits','Runs','RBI']].mean()

#add dummy variables for categorical columns 
df=pd.get_dummies(df,columns=["League", "Division", "NewLeague"], drop_first=True).astype(int)

#modeling the data
y = df['Hits']
x = df.drop(['Hits'])

#split the test and train data 
df_x_train, df_x_test, df_y_train, df_y_test = train_test_split(
    x, y, test_size=0.2, random_state=42)

#XGBoost model 
xgb_model=XGBRegressor().fit(df_x_train, df_y_train)
xgb_y_pred = xgb_model.predict(df_x_test)
r2_xgb = r2_score(df_y_test, xgb_y_pred)
print("R2 Score for XGBoost model:",r2_xgb)

#linear regression 
lm = LinearRegression()
lr_model = lr_model.fit(x,y)
lr_pred = lr_model.predict(x)
r2_lr = r2_score(y, lr_pred)
print("R2 Score for Linear Regression model:",r2_lr) 

#KNN 
knn_model = KNeighborsRegressor().fit(df_x_train, df_y_train)
print("Number of Neighbors: ", knn_model.n_neighbors)
knn_y_pred=knn_model.predict(df_x_train)
knn_y_pred_t=knn_model.predict(df_x_test)
knn_rmse_train=np.sqrt(mean_squared_error(df_y_train, knn_y_pred))
knn_rmse_test=np.sqrt(mean_squared_error(df_y_test, knn_y_pred_t))
r_kare_train=lr_model.score(df_x_train, df_y_train)
r_kare_test=lr_model.score(df_x_test, df_y_test)
print("knn rmse train: ", knn_rmse_train)
print("knn rmse test: ", knn_rmse_test)

